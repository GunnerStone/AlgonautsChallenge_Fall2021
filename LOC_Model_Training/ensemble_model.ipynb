{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "#define variables specific to this model\n",
    "subject = 'sub01'\n",
    "roi = 'LOC'\n",
    "ensemble_model_name = 'model_weights_{}_{}_ensemble.pt'.format(subject, roi)\n",
    "\n",
    "RAW_model_name = 'model_weights_{}_{}_RAW.pt'.format(subject, roi)\n",
    "RAFT_model_name = 'model_weights_{}_{}_RAFT.pt'.format(subject, roi)\n",
    "BDCN_model_name = 'model_weights_{}_{}_BDCN.pt'.format(subject, roi)\n",
    "MFCC_model_name = 'model_weights_{}_{}_MFCC.pt'.format(subject, roi)\n",
    "\n",
    "# define global variables / hyperparameters\n",
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# detect if GPU/CPU device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('CUDA available:', use_cuda)\n",
    "\n",
    "# set RNG seed for reproducibility\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# setup gpu things\n",
    "dtype = 'float32' if use_cuda else 'float64' # GPU does better with float32 numbers\n",
    "torchtype = {'float32': torch.float32, 'float64': torch.float64}[dtype]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# flush out the cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes arrays x1, y1, x2, y2\n",
    "# each y has dimensions (num_samples, num_classes)  \n",
    "# finds the similar labels in y1 and y2\n",
    "# uses the indices of similar labels to find the corresponding x1 and x2\n",
    "# returns the x1, x2, y1\n",
    "def find_similar_labels(x1, y1, x2, y2):\n",
    "    # for every label in y1, see if there is a similar label in y2\n",
    "    # if there is, add the corresponding x1 and x2 to the list\n",
    "    # return the list of x1, x2, y1, y2\n",
    "    x1_list = []\n",
    "    x2_list = []\n",
    "    y1_list = []\n",
    "    for i, label in enumerate(y1):\n",
    "        # labels are both floats, so check if they are close enough\n",
    "        # if they are close enough, add the corresponding x1 and x2 to the list\n",
    "        # if they are not close enough, do nothing\n",
    "        # if there is no similar label, do nothing\n",
    "        similar_label_idx = -1\n",
    "        similar_label = False\n",
    "        for j, label2 in enumerate(y2):\n",
    "            if np.allclose(label, label2, atol=0.1):\n",
    "                similar_label = True\n",
    "                similar_label_idx = j\n",
    "                break\n",
    "        if similar_label:\n",
    "            x1_list.append(x1[i])\n",
    "            x2_list.append(x2[j])\n",
    "            y1_list.append(label)\n",
    "    return np.array(x1_list), np.array(x2_list), np.array(y1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar labels between MFCC and RAW\n",
      "Finding similar labels between MFCC and RAFT\n",
      "Finding similar labels between MFCC and BDCN\n",
      "Number of RAW training samples:  598\n",
      "Number of MFCC training samples:  598\n",
      "Number of RAFT training samples:  598\n",
      "Number of BDCN training samples:  598\n",
      "Number of voxel activations (classes):  1843\n",
      "Value range of labels:  0.0 1.0\n",
      "Number of voxel activations (classes):  1843\n",
      "RAW_training_data tensor dims: torch.Size([598, 225, 32, 32])\n",
      "RAFT_training_data tensor dims: torch.Size([598, 222, 32, 32])\n",
      "BDCN_training_data tensor dims: torch.Size([598, 75, 32, 32])\n",
      "MFCC_training_data tensor dims: torch.Size([598, 1, 39, 261])\n",
      "training_labels tensor dims: torch.Size([598, 1843])\n",
      "Value range of labels:  0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training a RNN with PyTorch for roi V1 with RAW data\n",
    "\n",
    "# Load the entire training data into main memory\n",
    "# This is a huge dataset, so we need to do this in chunks\n",
    "\n",
    "#isolate subject of interests' data\n",
    "num_subjects = 10\n",
    "soi = subject\n",
    "num_classes = -1\n",
    "\n",
    "# read in every npy file in the directory Gunners_training_data/V1/RAW and store them in a list \n",
    "RAW_training_data = []\n",
    "RAW_training_labels = []\n",
    "\n",
    "RAFT_training_data = []\n",
    "RAFT_training_labels = []\n",
    "\n",
    "BDCN_training_data = []\n",
    "BDCN_training_labels = []\n",
    "\n",
    "MFCC_training_data = []\n",
    "MFCC_training_labels = []\n",
    "\n",
    "# load in every Nth file in the directory\n",
    "culling_scale = 1\n",
    "\n",
    "preprocessing = 'MFCC'\n",
    "input_data_dims = (39,261)\n",
    "input_channels = 1\n",
    "# for each file in the MFCC directory\n",
    "for i, file in enumerate(os.listdir('../Gunners_training_data/{}/{}'.format(roi, preprocessing))):\n",
    "    # if the file name contains the soi string\n",
    "    if not soi in file:\n",
    "        continue\n",
    "    # if the file is a .npy file\n",
    "    if file.endswith('.npy'):\n",
    "        # read in the file\n",
    "        data = np.load('../Gunners_training_data/{}/{}/'.format(roi,preprocessing) + file, allow_pickle=True)\n",
    "        \n",
    "        # print out first voxel label\n",
    "        # if i == 0:\n",
    "        #     print(data[0][1][0])\n",
    "\n",
    "        # for each sample, make sure its dimensions are correct, if not then skip it\n",
    "        if data[0][0].shape != input_data_dims:\n",
    "            # if the shape is larger than the input_data_dims, then crop it\n",
    "            if data[0][0].shape[1] > input_data_dims[1]:\n",
    "                data[0][0] = data[0][0][:,:input_data_dims[1]]\n",
    "            if data[0][0].shape != input_data_dims:\n",
    "                continue\n",
    "\n",
    "        # for each sample, add the data to the training_data list\n",
    "        data[0][0] = np.expand_dims(data[0][0],axis=0)\n",
    "        MFCC_training_data.append(data[0][0])\n",
    "        # for each sample, add the label to the training_labels list\n",
    "        MFCC_training_labels.append(data[0][1])\n",
    "\n",
    "num_classes = len(MFCC_training_labels[0])\n",
    "\n",
    "preprocessing = 'RAW'\n",
    "input_data_dims = (32,32,225)\n",
    "input_channels = 225\n",
    "# for each file in the RAW directory\n",
    "for i, file in enumerate(os.listdir('../Gunners_training_data/{}/{}'.format(roi, preprocessing))):\n",
    "    # if the file name contains the soi string\n",
    "    if not soi in file:\n",
    "        continue\n",
    "    # if the file is a .npy file\n",
    "    if file.endswith('.npy'):\n",
    "        # read in the file\n",
    "        data = np.load('../Gunners_training_data/{}/{}/'.format(roi,preprocessing) + file, allow_pickle=True)\n",
    "        \n",
    "        # print out first voxel label\n",
    "        # if i == 0:\n",
    "        #     print(data[0][1][0])\n",
    "\n",
    "        # for each sample, make sure its dimensions are 32x32x225, if not then skip it\n",
    "        if data[0][0].shape != input_data_dims:\n",
    "            continue\n",
    "        \n",
    "        # for each sample, add the data to the training_data list\n",
    "        RAW_training_data.append(data[0][0])\n",
    "\n",
    "        # for each label, add the data to the training_data list\n",
    "        RAW_training_labels.append(data[0][1])\n",
    "\n",
    "# cull MFCCS that dont have RAW data and vice versa\n",
    "MFCC_training_data = np.array(MFCC_training_data)\n",
    "MFCC_training_labels = np.array(MFCC_training_labels)\n",
    "RAW_training_data = np.array(RAW_training_data)\n",
    "RAW_training_labels = np.array(RAW_training_labels)\n",
    "\n",
    "print(\"Finding similar labels between MFCC and RAW\")\n",
    "MFCC_training_data, RAW_training_data, MFCC_training_labels = find_similar_labels(MFCC_training_data, MFCC_training_labels, RAW_training_data, RAW_training_labels)\n",
    "\n",
    "preprocessing = 'RAFT'\n",
    "input_data_dims = (32,32,222)\n",
    "input_channels = 222\n",
    "# for each file in the RAW directory\n",
    "for i, file in enumerate(os.listdir('../Gunners_training_data/{}/{}'.format(roi, preprocessing))):\n",
    "    # if the file name contains the soi string\n",
    "    if not soi in file:\n",
    "        continue\n",
    "    # if the file is a .npy file\n",
    "    if file.endswith('.npy'):\n",
    "        # read in the file\n",
    "        data = np.load('../Gunners_training_data/{}/{}/'.format(roi,preprocessing) + file, allow_pickle=True)\n",
    "        \n",
    "        \n",
    "        # print out first voxel label\n",
    "        # if i == 0:\n",
    "        #     print(data[0][1][0])\n",
    "\n",
    "        # for each sample, make sure its dimensions are 32x32x225, if not then skip it\n",
    "        if data[0][0].shape != input_data_dims:\n",
    "            continue\n",
    "        \n",
    "        # for each sample, add the data to the training_data list\n",
    "        RAFT_training_data.append(data[0][0])\n",
    "\n",
    "        # for each label, add the data to the training_data list\n",
    "        RAFT_training_labels.append(data[0][1])\n",
    "\n",
    "\n",
    "# cull MFCCs/RAW that dont have RAFT data and vice versa\n",
    "RAFT_training_data = np.array(RAFT_training_data)\n",
    "RAFT_training_labels = np.array(RAFT_training_labels)\n",
    "\n",
    "print(\"Finding similar labels between MFCC and RAFT\")\n",
    "RAFT_training_data, MFCC_training_data, MFCC_training_labels = find_similar_labels(RAFT_training_data, RAFT_training_labels, MFCC_training_data, MFCC_training_labels)\n",
    "\n",
    "preprocessing = 'BDCN'\n",
    "input_data_dims = (32,32,75)\n",
    "input_channels = 75\n",
    "# for each file in the RAW directory\n",
    "for i, file in enumerate(os.listdir('../Gunners_training_data/{}/{}'.format(roi, preprocessing))):\n",
    "    # if the file name contains the soi string\n",
    "    if not soi in file:\n",
    "        continue\n",
    "    # if the file is a .npy file\n",
    "    if file.endswith('.npy'):\n",
    "        # read in the file\n",
    "        data = np.load('../Gunners_training_data/{}/{}/'.format(roi,preprocessing) + file, allow_pickle=True)\n",
    "        \n",
    "        \n",
    "        # print out first voxel label\n",
    "        # if i == 0:\n",
    "        #     print(data[0][1][0])\n",
    "\n",
    "        # for each sample, make sure its dimensions are 32x32x225, if not then skip it\n",
    "        if data[0][0].shape != input_data_dims:\n",
    "            continue\n",
    "        \n",
    "        # for each sample, add the data to the training_data list\n",
    "        BDCN_training_data.append(data[0][0])\n",
    "\n",
    "        # for each label, add the data to the training_data list\n",
    "        BDCN_training_labels.append(data[0][1])\n",
    "\n",
    "\n",
    "# cull MFCCs/RAW that dont have RAFT data and vice versa\n",
    "BDCN_training_data = np.array(BDCN_training_data)\n",
    "BDCN_training_labels = np.array(BDCN_training_labels)\n",
    "\n",
    "print(\"Finding similar labels between MFCC and BDCN\")\n",
    "BDCN_training_data, MFCC_training_data, MFCC_training_labels = find_similar_labels(BDCN_training_data, BDCN_training_labels, MFCC_training_data, MFCC_training_labels)\n",
    "\n",
    "print('Number of RAW training samples: ', len(RAW_training_data))\n",
    "print('Number of MFCC training samples: ', len(MFCC_training_data))\n",
    "print('Number of RAFT training samples: ', len(RAFT_training_data))\n",
    "print('Number of BDCN training samples: ', len(BDCN_training_data))\n",
    "print('Number of voxel activations (classes): ', num_classes)\n",
    "\n",
    "# Only keep MFFC_training_labels; release memory of other label arrays\n",
    "RAW_training_labels = None\n",
    "RAFT_training_labels = None\n",
    "BDCN_training_labels = None\n",
    "\n",
    "#normalize all labels to be between -1 and 1\n",
    "MFCC_training_labels = np.array(MFCC_training_labels)\n",
    "MFCC_training_labels = (MFCC_training_labels - np.min(MFCC_training_labels)) / (np.max(MFCC_training_labels) - np.min(MFCC_training_labels))\n",
    "#print the value range of the labels\n",
    "print('Value range of labels: ', np.min(MFCC_training_labels), np.max(MFCC_training_labels))\n",
    "num_classes = MFCC_training_labels[0].shape[0]\n",
    "print('Number of voxel activations (classes): ', num_classes)\n",
    "    \n",
    "# verify the data is loaded correctly and is in numpy arrays\n",
    "RAW_training_data = np.array(RAW_training_data)\n",
    "RAFT_training_data = np.array(RAFT_training_data)\n",
    "BDCN_training_data = np.array(BDCN_training_data)\n",
    "MFCC_training_data = np.array(MFCC_training_data)\n",
    "\n",
    "# combine all training data into one array for a pytorch Dataset object\n",
    "RAW_training_data = torch.tensor(RAW_training_data).type(torchtype)\n",
    "RAFT_training_data = torch.tensor(RAFT_training_data).type(torchtype)\n",
    "BDCN_training_data = torch.tensor(BDCN_training_data).type(torchtype)\n",
    "MFCC_training_data = torch.tensor(MFCC_training_data).type(torchtype)\n",
    "training_labels = torch.tensor(MFCC_training_labels).type(torchtype)\n",
    "\n",
    "# permute the data so that the first dimension is the number of samples, the second is the number of channels\n",
    "# not viable for MFCC 2d data\n",
    "RAW_training_data = RAW_training_data.permute(0,3,1,2)\n",
    "RAFT_training_data = RAFT_training_data.permute(0,3,1,2)\n",
    "BDCN_training_data = BDCN_training_data.permute(0,3,1,2)\n",
    "\n",
    "\n",
    "#print the dims of training_data tensor\n",
    "print('RAW_training_data tensor dims:', RAW_training_data.shape)\n",
    "print('RAFT_training_data tensor dims:', RAFT_training_data.shape)\n",
    "print('BDCN_training_data tensor dims:', BDCN_training_data.shape)\n",
    "print('MFCC_training_data tensor dims:', MFCC_training_data.shape)\n",
    "print('training_labels tensor dims:', training_labels.shape)\n",
    "\n",
    "# create a dataset from the tensors\n",
    "RAW_dataset = TensorDataset(RAW_training_data,training_labels)\n",
    "RAFT_dataset = TensorDataset(RAFT_training_data,training_labels)\n",
    "BDCN_dataset = TensorDataset(BDCN_training_data,training_labels)\n",
    "MFCC_dataset = TensorDataset(MFCC_training_data,training_labels)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "train_size = int(0.8 * len(RAW_training_data))\n",
    "valid_size = len(RAW_training_data) - train_size\n",
    "\n",
    "# create training and validation sets\n",
    "RAW_dataset, RAW_validation_data = torch.utils.data.random_split(RAW_dataset, [train_size, valid_size])\n",
    "RAFT_dataset, RAFT_validation_data = torch.utils.data.random_split(RAFT_dataset, [train_size, valid_size])\n",
    "BDCN_dataset, BDCN_validation_data = torch.utils.data.random_split(BDCN_dataset, [train_size, valid_size])\n",
    "MFCC_dataset, MFCC_validation_data = torch.utils.data.random_split(MFCC_dataset, [train_size, valid_size])\n",
    "\n",
    "# # combine all the training datasets into a big one\n",
    "# train_data = [RAW_dataset, RAFT_dataset, BDCN_dataset, MFCC_dataset]\n",
    "# # concatenate all the validation datasets\n",
    "# valid_data = torch.utils.data.ConcatDataset([RAW_validation_data, RAFT_validation_data, BDCN_validation_data, MFCC_validation_data])\n",
    "\n",
    "# print out the range of values for labels\n",
    "print('Value range of labels: ', np.min(MFCC_training_labels), np.max(MFCC_training_labels))\n",
    "\n",
    "\n",
    "# create training and validation dataloaders\n",
    "\n",
    "RAW_train_loader = DataLoader(RAW_dataset, batch_size = batch_size, shuffle=True)\n",
    "RAFT_train_loader = DataLoader(RAFT_dataset, batch_size = batch_size, shuffle=True)\n",
    "BDCN_train_loader = DataLoader(BDCN_dataset, batch_size = batch_size, shuffle=True)\n",
    "MFCC_train_loader = DataLoader(MFCC_dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "RAW_val_loader = DataLoader(RAW_validation_data, batch_size = batch_size, shuffle=False)\n",
    "RAFT_val_loader = DataLoader(RAFT_validation_data, batch_size = batch_size, shuffle=False)\n",
    "BDCN_val_loader = DataLoader(BDCN_validation_data, batch_size = batch_size, shuffle=False)\n",
    "MFCC_val_loader = DataLoader(MFCC_validation_data, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelRAW, modelRAFT, modelBDCN, modelMFCC, nb_classes=num_classes):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelRAW = modelRAW\n",
    "        self.modelRAFT = modelRAFT\n",
    "        self.modelBDCN = modelBDCN\n",
    "        self.modelMFCC = modelMFCC\n",
    "        # Remove last linear layer\n",
    "        # self.modelRAW.fc = nn.Identity()\n",
    "        # self.modelBDCN.fc = nn.Identity()\n",
    "        # self.modelRAFT.fc = nn.Identity()\n",
    "        # self.modelMFCC.fc = nn.Identity()\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier1 = nn.Linear(num_classes*4, 2048)\n",
    "        self.classifier2 = nn.Linear(2048, nb_classes)\n",
    "        \n",
    "    def forward(self, dataRAW, dataRAFT, dataBDCN, dataMFCC):\n",
    "        x1 = self.modelRAW(dataRAW)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.modelBDCN(dataBDCN)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = self.modelRAFT(dataRAFT)  \n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        x4 = self.modelMFCC(dataMFCC)  \n",
    "        x4 = x4.view(x4.size(0), -1)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1).to(device)\n",
    "        # print(x.shape)\n",
    "        # print(x.shape)\n",
    "        x = torch.sigmoid(self.classifier2(F.relu(self.classifier1(F.relu(x)))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the RAW model\n",
    "# define RNN model with 225 channels\n",
    "input_channels = 225\n",
    "modelRAW = timm.create_model('densenet121', num_classes=num_classes, in_chans=input_channels, pretrained=False).to(device)\n",
    "modelRAW = nn.Sequential(modelRAW, nn.Sigmoid())\n",
    "\n",
    "modelRAW.eval()\n",
    "# make the model use floats\n",
    "modelRAW.float()\n",
    "\n",
    "# load pretrained weighst from the file\n",
    "modelRAW.load_state_dict(torch.load('{}'.format(RAW_model_name)))\n",
    "\n",
    "# define optimizer\n",
    "optimizerRAW = torch.optim.Adam(modelRAW.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for Learning Rate\n",
    "schedulerRAW = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerRAW, 'min', patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the RAFT model\n",
    "# define RNN model with 222 channels\n",
    "input_channels = 222\n",
    "modelRAFT = timm.create_model('cspresnext50', num_classes=num_classes, in_chans=input_channels, pretrained=False).to(device)\n",
    "modelRAFT = nn.Sequential(modelRAFT, nn.Sigmoid())\n",
    "\n",
    "modelRAFT.eval()\n",
    "# make the model use floats\n",
    "modelRAFT.float()\n",
    "\n",
    "# load pretrained weighst from the file\n",
    "modelRAFT.load_state_dict(torch.load('{}'.format(RAFT_model_name)))\n",
    "\n",
    "# define optimizer\n",
    "optimizerRAFT = torch.optim.Adam(modelRAFT.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for Learning Rate\n",
    "schedulerRAFT = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerRAFT, 'min', patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the BDCN model\n",
    "# define RNN model with 222 channels\n",
    "input_channels = 75\n",
    "modelBDCN = timm.create_model('densenet121', num_classes=num_classes, in_chans=input_channels, pretrained=False).to(device)\n",
    "modelBDCN = nn.Sequential(modelBDCN, nn.Sigmoid())\n",
    "\n",
    "modelBDCN.eval()\n",
    "# make the model use floats\n",
    "modelBDCN.float()\n",
    "\n",
    "# load pretrained weighst from the file\n",
    "modelBDCN.load_state_dict(torch.load('{}'.format(BDCN_model_name)))\n",
    "\n",
    "# define optimizer\n",
    "optimizerBDCN = torch.optim.Adam(modelBDCN.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for Learning Rate\n",
    "schedulerBDCN = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerBDCN, 'min', patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the MFCC model\n",
    "# define RNN model with 222 channels\n",
    "input_channels = 1\n",
    "modelMFCC = timm.create_model('densenet121', num_classes=num_classes, in_chans=input_channels, pretrained=False).to(device)\n",
    "modelMFCC = nn.Sequential(modelMFCC, nn.Sigmoid())\n",
    "modelMFCC.eval()\n",
    "# make the model use floats\n",
    "modelMFCC.float()\n",
    "\n",
    "# load pretrained weighst from the file\n",
    "modelMFCC.load_state_dict(torch.load('{}'.format(MFCC_model_name)))\n",
    "\n",
    "# define optimizer\n",
    "optimizerMFCC = torch.optim.Adam(modelMFCC.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for Learning Rate\n",
    "schedulerMFCC = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerMFCC, 'min', patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a loss function that is 1 - the correlation coefficient\n",
    "def corrcoef_loss_function(output, target):\n",
    "    x = output\n",
    "    y = target\n",
    "\n",
    "    vx = x - torch.mean(x)\n",
    "    vy = y - torch.mean(y)\n",
    "\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    # mse_loss = torch.mean((output - target) ** 2)\n",
    "    return (1 - cost)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ensemble model\n",
    "model = MyEnsemble(modelRAW, modelRAFT, modelBDCN, modelMFCC)\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for Learning Rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
    "\n",
    "# define loss function for multi-variable regression\n",
    "loss_fn = corrcoef_loss_function\n",
    "\n",
    "if use_cuda:\n",
    "    #put model on gpu\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a89732b87340ccbfec86004d2e1304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Best validation loss:  1.0705631449818611\n",
      "Epoch of best validation loss:  12\n"
     ]
    }
   ],
   "source": [
    "# keep track of training/validation loss\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# train the model\n",
    "#progress bar for training\n",
    "pbar = tqdm(range(num_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    # keep track of training and validation accuracy\n",
    "    train_accuracy = 0.0\n",
    "    valid_accuracy = 0.0\n",
    "    \n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # train the model for one epoch\n",
    "    for RAW_data, RAFT_data, BDCN_data, MFCC_data in zip(RAW_train_loader, RAFT_train_loader, BDCN_train_loader, MFCC_train_loader):\n",
    "        image_batch1, labels = RAW_data\n",
    "        image_batch2, _ = RAFT_data\n",
    "        image_batch3, _ = BDCN_data\n",
    "        image_batch4, _ = MFCC_data\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if use_cuda:\n",
    "            image_batch1, labels = image_batch1.to(device), labels.to(device)\n",
    "            image_batch2, image_batch3, image_batch4 = image_batch2.to(device), image_batch3.to(device), image_batch4.to(device)\n",
    "            \n",
    "            \n",
    "        # zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(dataRAW = image_batch1, dataRAFT = image_batch2, dataBDCN = image_batch3, dataMFCC = image_batch4)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate the training loss\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # evaluate the model on the validation set\n",
    "    for RAW_data, RAFT_data, BDCN_data, MFCC_data in zip(RAW_val_loader, RAFT_val_loader, BDCN_val_loader, MFCC_val_loader):\n",
    "        \n",
    "        image_batch1, labels = RAW_data\n",
    "        image_batch2, _ = RAFT_data\n",
    "        image_batch3, _ = BDCN_data\n",
    "        image_batch4, _ = MFCC_data\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if use_cuda:\n",
    "            image_batch1, labels = image_batch1.to(device), labels.to(device)\n",
    "            image_batch2, image_batch3, image_batch4 = image_batch2.to(device), image_batch3.to(device), image_batch4.to(device)\n",
    "            #put model on gpu\n",
    "            model = model.to(device)\n",
    "        \n",
    "        # validation forward pass\n",
    "        output = model(image_batch1, image_batch2, image_batch3, image_batch4)\n",
    "\n",
    "        # calculate the validation loss\n",
    "        valid_loss += loss_fn(output, labels).item()\n",
    "    \n",
    "    # calculate the average training loss and accuracy\n",
    "    train_loss = train_loss/len(RAW_train_loader)\n",
    "\n",
    "    # calculate the average validation loss and accuracy\n",
    "    valid_loss = valid_loss/len(RAW_val_loader)\n",
    "\n",
    "    # ping the learning rate scheduler\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # append the training and validation loss and accuracy to the lists\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # if current validation loss was best so far, save the model weights in memory\n",
    "    best_valid_loss = min(valid_losses)\n",
    "    if valid_loss == best_valid_loss:\n",
    "        my_best_weights = model.state_dict() \n",
    "    \n",
    "    # display the epoch training loss\n",
    "    pbar.set_postfix({\n",
    "                    'Epoch':'{}/{}'.format(epoch+1, num_epochs), \n",
    "                    'Training Loss': '{:.4f}'.format(train_loss) , \n",
    "                    'Validation loss' : '{:.4f}'.format(valid_loss)})\n",
    "# assign the best weights to the model\n",
    "model.load_state_dict(my_best_weights)\n",
    "\n",
    "#print the epoch of the best validation loss\n",
    "print('Best validation loss: ', min(valid_losses))\n",
    "print('Epoch of best validation loss: ', valid_losses.index(min(valid_losses))+1)\n",
    "# print the model summary\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model weights to the model\n",
    "model.load_state_dict(my_best_weights)\n",
    "# save the best model weights to a file\n",
    "torch.save(model.state_dict(), '{}'.format(ensemble_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training and validation loss and accuracy and a vertical line on the x-axis at the epoch of the best validation loss\n",
    "best_epoch = valid_losses.index(min(valid_losses))+1\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1,num_epochs+1), valid_losses, label='Validation Loss')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--', label='Best Validation Loss Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the ensemble model from the file\n",
    "model.load_state_dict(torch.load('{}'.format(ensemble_model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35927555\n",
      "0.46114898\n",
      "0.50010216\n",
      "0.56170374\n",
      "0.5558122\n",
      "0.47700733\n",
      "0.46272236\n",
      "0.4178347\n",
      "Highest Correlation Coefficient:  0.29220878607790635\n",
      "Lowest Correlation Coefficient:  -0.23609817172756536\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Correlation Coefficient:  -0.023169429124057415\n",
      "Mean Correlation Coefficient:  -0.023169429124057415\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# display a side by side comparison of the original label and the predicted label\n",
    "def display_side_by_side(original, prediction):\n",
    "    #add title to the figure\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(original)\n",
    "    ax.set_title('Original')\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(prediction)\n",
    "    ax.set_title('Prediction')\n",
    "    # calculate the mean squared error\n",
    "    mse = (original - prediction)**2\n",
    "    # display mse next to the other comparisons\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    ax.set_title('MSE: {:.4f}'.format (mse.mean()))\n",
    "    ax.imshow(mse)\n",
    "    plt.show()\n",
    "\n",
    "# display a figure of the mean squared error between the original label and the predicted label on matplotlib\n",
    "def display_mse(original, prediction):\n",
    "    mse = np.mean((original - prediction)**2)\n",
    "    print('Mean Squared Error: ', mse)\n",
    "    plt.imshow((original - prediction)**2)\n",
    "    plt.show()\n",
    "\n",
    "# print(training_labels[0].unsqueeze(0).numpy().shape)\n",
    "\n",
    "# resized_original = training_labels[0].unsqueeze(0).numpy().reshape(8,29)\n",
    "# resized_prediction = model(training_data[0].unsqueeze(0).to(device)).detach().cpu().numpy().reshape(8,29)\n",
    "\n",
    "#draw a correlation coefficient graph between the original label and the predicted label\n",
    "def draw_correlation_coefficient(original, prediction):\n",
    "    # calculate the correlation coefficient\n",
    "    corr_coeff = np.corrcoef(original, prediction)[0,1]\n",
    "    # display the correlation coefficient\n",
    "    print('Correlation Coefficient: ', corr_coeff)\n",
    "    # plot the correlation coefficient graph\n",
    "    plt.plot(original, prediction, 'o')\n",
    "    plt.xlabel('Original')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title('Correlation Coefficient: {:.2f}'.format(corr_coeff))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#print out value ranges of prediction\n",
    "# print('Prediction Range: ', np.min(resized_prediction), np.max(resized_prediction))\n",
    "\n",
    "# display a side by side comparison of the original label and the predicted label\n",
    "# display_side_by_side(resized_original,resized_prediction)\n",
    "# display_mse(resized_original,resized_prediction)\n",
    "\n",
    "# draw_correlation_coefficient(training_labels[0].unsqueeze(0).numpy(),model(training_data[0].unsqueeze(0).to(device)).detach().cpu().numpy())\n",
    "\n",
    "#find out the correlation coefficient between the original label and the predicted label for the entire dataset\n",
    "def find_correlation_coeff(model):\n",
    "    # calculate the correlation coefficient\n",
    "    corr_coeff_list = []\n",
    "    # separate the pytorch dataset into the data and labels\n",
    "    # set the model to evaluation mode\n",
    "    \n",
    "    \n",
    "    # evaluate the model on the validation set\n",
    "    for RAW_data, RAFT_data, BDCN_data, MFCC_data in zip(RAW_val_loader, RAFT_val_loader, BDCN_val_loader, MFCC_val_loader):\n",
    "        \n",
    "        image_batch1, labels = RAW_data\n",
    "        image_batch2, _ = RAFT_data\n",
    "        image_batch3, _ = BDCN_data\n",
    "        image_batch4, _ = MFCC_data\n",
    "        \n",
    "        print(labels.cpu().numpy()[0][0])\n",
    "        # print the range of labels\n",
    "\n",
    "\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if use_cuda:\n",
    "            image_batch1, labels = image_batch1.to(device), labels.to(device)\n",
    "            image_batch2, image_batch3, image_batch4 = image_batch2.to(device), image_batch3.to(device), image_batch4.to(device)\n",
    "            #put model on gpu\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "        \n",
    "        # validation forward pass\n",
    "        output = model(image_batch1, image_batch2, image_batch3, image_batch4)\n",
    "        # calculate the correlation coefficient for every image in the batch\n",
    "        # for every image in the batch\n",
    "        for i in range(len(output)):\n",
    "            # calculate the correlation coefficient\n",
    "            corr_coeff = np.corrcoef(labels.cpu().numpy()[i].T, output[i].detach().cpu().numpy().T)[0,1]\n",
    "            # append the correlation coefficient to the list\n",
    "            corr_coeff_list.append(corr_coeff)\n",
    "    # calculate the mean correlation coefficient\n",
    "    mean_corr_coeff = np.mean(corr_coeff_list)\n",
    "    #print the highest correlation coefficient and lowest correlation coefficient\n",
    "    print('Highest Correlation Coefficient: ', max(corr_coeff_list))\n",
    "    print('Lowest Correlation Coefficient: ', min(corr_coeff_list))\n",
    "\n",
    "    # plot a histogram of the correlation coefficients\n",
    "    plt.hist(corr_coeff_list, bins=20)\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Correlation Coefficients')\n",
    "    plt.show()\n",
    "    \n",
    "    # display the mean correlation coefficient\n",
    "    print('Mean Correlation Coefficient: ', mean_corr_coeff)\n",
    "    return mean_corr_coeff\n",
    "\n",
    "model.eval()\n",
    "print ( 'Mean Correlation Coefficient: ', find_correlation_coeff(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56b845d6abd23659834aae6421cf8955130b9ac3c06659d895784ecea1539adc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('algo': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
